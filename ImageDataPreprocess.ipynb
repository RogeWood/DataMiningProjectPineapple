{"cells":[{"cell_type":"markdown","metadata":{"id":"ojwVhnFBEtSF"},"source":["### 輸入資料"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2593,"status":"ok","timestamp":1716631214464,"user":{"displayName":"木小也","userId":"02664299348038047142"},"user_tz":-480},"id":"TTuZQn01UrJn","outputId":"dc3afc7b-5fa2-428e-94fd-9fb61620cf90"},"outputs":[{"name":"stdout","output_type":"stream","text":["hello world\n"]}],"source":["import os\n","import numpy as np\n","import pandas as pd\n","from tensorflow import keras\n","# from google.colab import drive\n","\n","# drive.mount('/content/drive')\n","print(\"hello world\")"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2255866,"status":"ok","timestamp":1716633470326,"user":{"displayName":"木小也","userId":"02664299348038047142"},"user_tz":-480},"id":"WJ-f3q7G3007","outputId":"d6093f91-0439-4d56-f27b-7011a7d5ba95"},"outputs":[{"name":"stdout","output_type":"stream","text":["01.jpg [] 0015 {'loc-2'} pine-bottom\n","03.jpg [] 0017 {'loc-2'} pine-bottom\n","02.jpg [] 0050 {'loc-1'} pine-bottom\n","01.jpg [] 0063 {'loc-2'} pine-bottom\n","03.jpg [] 0067 {'loc-1'} pine-bottom\n","02.jpg [] 0071 {'loc-2'} pine-bottom\n","04.jpg [] 0071 {'loc-2'} pine-bottom\n","01.jpg [] 0077 {'loc-1'} pine-bottom\n","02.jpg [] 0077 {'loc-1'} pine-bottom\n","03.jpg [] 0077 {'loc-1'} pine-bottom\n","01.jpg [] 0088 {'loc-2'} pine-bottom\n","01.jpg [] 0089 {'loc-2'} pine-bottom\n","03.jpg [] 0089 {'loc-2'} pine-bottom\n","01.jpg [] 0096 {'loc-1'} pine-bottom\n","04.jpg [] 0099 {'loc-1'} pine-bottom\n","04.jpg [] 0106 {'loc-2'} pine-bottom\n","01.jpg [] 0107 {'loc-2'} pine-bottom\n","03.jpg [] 0107 {'loc-2'} pine-bottom\n","01.jpg [] 0109 {'loc-2'} pine-bottom\n","03.jpg [] 0115 {'loc-1'} pine-bottom\n","01.jpg [] 0119 {'loc-2'} pine-bottom\n","03.jpg [] 0130 {'loc-2'} pine-bottom\n","01.jpg [] 0139 {'loc-1'} pine-bottom\n","02.jpg [] 0139 {'loc-1'} pine-bottom\n","01.jpg [] 0145 {'loc-1'} pine-bottom\n","01.jpg [] 0150 {'loc-2'} pine-bottom\n","02.jpg [] 0150 {'loc-2'} pine-bottom\n","03.jpg [] 0161 {'loc-2'} pine-bottom\n","01.jpg [] 0181 {'loc-2'} pine-bottom\n","03.jpg [] 0192 {'loc-2'} pine-bottom\n","02.jpg [] 0193 {'loc-1'} pine-bottom\n","03.jpg [] 0193 {'loc-1'} pine-bottom\n","03.jpg [] 0195 {'loc-1'} pine-bottom\n","01.jpg [] 0195 {'loc-2'} pine-bottom\n","02.jpg [] 0195 {'loc-2'} pine-bottom\n","03.jpg [] 0195 {'loc-2'} pine-bottom\n","03.jpg [] 0202 {'loc-2'} pine-bottom\n","04.jpg [] 0209 {'loc-2'} pine-bottom\n","01.jpg [] 0221 {'loc-2'} pine-bottom\n","02.jpg [] 0221 {'loc-2'} pine-bottom\n","04.jpg [] 0221 {'loc-2'} pine-bottom\n","03.jpg [] 0229 {'loc-2'} pine-bottom\n","01.jpg [] 0237 {'loc-1'} pine-bottom\n","02.jpg [] 0237 {'loc-1'} pine-bottom\n","01.jpg [] 0246 {'loc-1'} pine-bottom\n","01.jpg [] 0248 {'loc-2'} pine-bottom\n","01.jpg [] 0251 {'loc-2'} pine-bottom\n","02.jpg [] 0253 {'loc-1'} pine-bottom\n","04.jpg [] 0254 {'loc-2'} pine-bottom\n","04.jpg [] 0280 {'loc-2'} pine-bottom\n","03.jpg [] 0284 {'loc-2'} pine-bottom\n","01.jpg [] 0285 {'loc-2'} pine-bottom\n","03.jpg [] 0285 {'loc-2'} pine-bottom\n","02.jpg [] 0300 {'loc-2'} pine-bottom\n","03.jpg [] 0300 {'loc-2'} pine-bottom\n","01.jpg [] 0313 {'loc-2'} pine-bottom\n","04.jpg [] 0313 {'loc-2'} pine-bottom\n","01.jpg [] 0331 {'loc-2'} pine-bottom\n","03.jpg [] 0331 {'loc-2'} pine-bottom\n","02.jpg [] 0333 {'loc-2'} pine-bottom\n","03.jpg [] 0356 {'loc-1'} pine-bottom\n","01.jpg [] 0365 {'loc-1'} pine-bottom\n","03.jpg [] 0365 {'loc-1'} pine-bottom\n","03.jpg [] 0377 {'loc-1'} pine-bottom\n","03.jpg [] 0378 {'loc-1'} pine-bottom\n","04.jpg [] 0408 {'loc-1'} pine-bottom\n","04.jpg [] 0409 {'loc-2'} pine-bottom\n","01.jpg [] 0422 {'loc-2'} pine-bottom\n","04.jpg [] 0422 {'loc-2'} pine-bottom\n","01.jpg [] 0427 {'loc-1'} pine-bottom\n","03.jpg [] 0427 {'loc-1'} pine-bottom\n","02.jpg [] 0442 {'loc-1'} pine-bottom\n","03.jpg [] 0447 {'loc-2'} pine-bottom\n","04.jpg [] 0447 {'loc-2'} pine-bottom\n","02.jpg [] 0449 {'loc-2'} pine-bottom\n","03.jpg [] 0449 {'loc-2'} pine-bottom\n","04.jpg [] 0449 {'loc-2'} pine-bottom\n","02.jpg [] 0455 {'loc-1'} pine-bottom\n","03.jpg [] 0457 {'loc-2'} pine-bottom\n","04.jpg [] 0457 {'loc-2'} pine-bottom\n","01.jpg [] 0463 {'loc-2'} pine-bottom\n","03.jpg [] 0463 {'loc-2'} pine-bottom\n","01.jpg [] 0469 {'loc-2'} pine-bottom\n","04.jpg [] 0469 {'loc-2'} pine-bottom\n","04.jpg [] 0470 {'loc-2'} pine-bottom\n","03.jpg [] 0471 {'loc-2'} pine-bottom\n","04.jpg [] 0475 {'loc-1'} pine-bottom\n","02.jpg [] 0475 {'loc-2'} pine-bottom\n","01.jpg [] 0480 {'loc-2'} pine-bottom\n","03.jpg [] 0480 {'loc-2'} pine-bottom\n","04.jpg [] 0481 {'loc-1'} pine-bottom\n","02.jpg [] 0482 {'loc-1'} pine-bottom\n","03.jpg [] 0482 {'loc-1'} pine-bottom\n","04.jpg [] 0482 {'loc-1'} pine-bottom\n","01.jpg [] 0482 {'loc-2'} pine-bottom\n","03.jpg [] 0482 {'loc-2'} pine-bottom\n","04.jpg [] 0482 {'loc-2'} pine-bottom\n","01.jpg [] 0483 {'loc-2'} pine-bottom\n","02.jpg [] 0483 {'loc-2'} pine-bottom\n","04.jpg [] 0483 {'loc-2'} pine-bottom\n","03.jpg [] 0495 {'loc-1'} pine-bottom\n"]}],"source":["import re\n","mypath = 'K:\\\\DataMiningProject\\\\Training_set\\\\'\n","\n","x = []\n","y = []\n","\n","count = 0\n","for (dirpath, dirnames, filenames) in os.walk(mypath):\n","  dirpath_list = dirpath.split('\\\\')\n","  # if count > 20:\n","  #   break\n","\n","\n","  if len(dirpath_list) > 5:\n","    for f in filenames:\n","      if \".jpg\" in f:\n","\n","        if 'pine-bottom' in dirpath:\n","        # if 'pine-side' in dirpath:\n","          count += 1\n","          # if count > 20:\n","          #   break\n","\n","          print(f, dirnames, dirpath_list[3],{dirpath_list[4]}, dirpath_list[5])\n","          image_path = f'{dirpath}/{f}'\n","          image = keras.utils.load_img(image_path, color_mode=\"grayscale\", target_size=(360, 640))\n","          input_arr = np.array([keras.utils.img_to_array(image)])  # Convert single image to a batch.\n","          x.append(input_arr)\n","          y.append(f\"{dirpath_list[3]}_{dirpath_list[4]}_{dirpath_list[5]}_{f}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["### 訓練資料整合"]},{"cell_type":"markdown","metadata":{"id":"vcC1D0MM11Eq"},"source":["#### train_label"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1716633470326,"user":{"displayName":"木小也","userId":"02664299348038047142"},"user_tz":-480},"id":"2MhyXwEzLYD6","outputId":"4b2c2f81-0f6a-4822-8c8b-fd76bfd4cc4c"},"outputs":[{"name":"stdout","output_type":"stream","text":["       1  1.1\n","0      2    1\n","1      3    1\n","2      4    1\n","3      6    1\n","4      7    1\n","..   ...  ...\n","394  495    4\n","395  496    3\n","396  497    4\n","397  498    4\n","398  500    4\n","\n","[399 rows x 2 columns]\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>Classification</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>6</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>395</th>\n","      <td>495</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>396</th>\n","      <td>496</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>397</th>\n","      <td>497</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>398</th>\n","      <td>498</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>399</th>\n","      <td>500</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>400 rows × 2 columns</p>\n","</div>"],"text/plain":["      ID  Classification\n","0      1               1\n","1      2               1\n","2      3               1\n","3      4               1\n","4      6               1\n","..   ...             ...\n","395  495               4\n","396  496               3\n","397  497               4\n","398  498               4\n","399  500               4\n","\n","[400 rows x 2 columns]"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["\n","train_label = pd.read_csv(f'{mypath}/training_set_label.csv')\n","print(train_label)\n","train_label.rename(columns={'1': 'ID', '1.1': 'Classification'}, inplace=True)\n","\n","# 要插入的行的數據\n","new_row_data = {'ID': 1, 'Classification': 1}\n","new_row_df = pd.DataFrame([new_row_data])\n","\n","# concat 函數將新的行插入到 DataFrame 的最開頭\n","train_label = pd.concat([new_row_df, train_label], ignore_index=True)\n","\n","train_label.to_csv('train_label.csv', index=False)\n","train_label"]},{"cell_type":"markdown","metadata":{"id":"mWZ8FkfN17ch"},"source":["#### train_y"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1716633470326,"user":{"displayName":"木小也","userId":"02664299348038047142"},"user_tz":-480},"id":"LIhm_BzoG0SU"},"outputs":[],"source":["# 轉換 y 為 DataFrame\n","y_df = pd.DataFrame({'Folder': y})\n","y_df\n","# 函數，提取 Folder 的前四個字符\n","def extract_prefix(folder):\n","    return int(folder[:4])\n","\n","# ID = Folder 的前四個字符\n","y_df['ID'] = y_df['Folder'].apply(extract_prefix)\n","y_df.to_csv('y_img_test_data.csv', index=False)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Classification.shape:  (101,)\n","刪除 y_df[Classification] = NaN\n","(101, 3)\n","y data complete!\n"]}],"source":["\n","# sort y_df['ID']\n","y_df = y_df.sort_values(by='ID')\n","y_df = y_df.reset_index()\n","\n","# 將 train_label 中的 'Classification' 列值賦值給 y_df 中的 'Classification' 列\n","Classification = []\n","i = 0\n","j = 0\n","\n","numi = len(y_df)\n","numj = len(train_label)\n","\n","while (i < numi)&(j < numj):\n","  if y_df['ID'][i] == train_label['ID'][j]:\n","    Classification.append(train_label['Classification'][j])\n","    i = i+1\n","  elif y_df['ID'][i] < train_label['ID'][j]:\n","    i = i+1\n","    Classification.append('NaN')\n","  else:\n","    j = j+1\n","\n","# 顯示修改後的 DataFrame\n","y_df['Classification'] = Classification\n","\n","# 將 y_df 回復順序與 x_df 一致\n","y_df = y_df.sort_values(by='index')\n","y_df = y_df.reset_index(drop=True)\n","\n","# 刪除 index 行\n","y_df = y_df.drop(columns=['index'])\n","\n","# 新增 x_df['Classification']\n","Classification = y_df['Classification']\n","print(f'Classification.shape: ', Classification.shape)\n","\n","# 刪除 y_df['Classification'] = 'NaN'\n","y_df = y_df.dropna(subset=['Classification'])\n","print('刪除 y_df[Classification] = NaN')\n","print(y_df.shape)\n","\n","# 分類成 6 組\n","y_df12 = y_df[(y_df.Classification == 1) | (y_df.Classification == 2)]\n","y_df13 = y_df[(y_df.Classification == 1) | (y_df.Classification == 3)]\n","y_df14 = y_df[(y_df.Classification == 1) | (y_df.Classification == 4)]\n","\n","y_df23 = y_df[(y_df.Classification == 2) | (y_df.Classification == 3)]\n","y_df24 = y_df[(y_df.Classification == 2) | (y_df.Classification == 4)]\n","y_df34 = y_df[(y_df.Classification == 3) | (y_df.Classification == 4)]\n","\n","\n","# y_data.csv\n","y_df.to_csv('y_data.csv', index=False)\n","\n","y_df12.to_csv('y_data12.csv', index=False)\n","y_df13.to_csv('y_data13.csv', index=False)\n","y_df14.to_csv('y_data14.csv', index=False)\n","\n","y_df23.to_csv('y_data23.csv', index=False)\n","y_df24.to_csv('y_data24.csv', index=False)\n","y_df34.to_csv('y_data34.csv', index=False)\n","print('y data complete!')\n"]},{"cell_type":"markdown","metadata":{"id":"LointIez2u8a"},"source":["#### train_x"]},{"cell_type":"markdown","metadata":{"id":"z_QALV_y20lC"},"source":["x_padded"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9973,"status":"ok","timestamp":1716633480293,"user":{"displayName":"木小也","userId":"02664299348038047142"},"user_tz":-480},"id":"9sYUsoM7QILe","outputId":"2f1ec3f0-186e-43ba-d2dd-f2a8f3f7f1ea"},"outputs":[{"name":"stdout","output_type":"stream","text":["Padded x shape: (101, 1, 360, 640, 1)\n"]}],"source":["# 記錄每個數組的形狀\n","# shapes = [array.shape for array in x]\n","# print(\"x shape:\", shapes)\n","\n","# 將數據和標籤轉換為 NumPy 數組\n","# 找到最大形狀\n","max_shape = np.max([array.shape for array in x], axis=0)\n","\n","# 使用 np.pad 將每個數組填充到相同的形狀\n","x_padded = [np.pad(array, [(0, max_shape[0] - array.shape[0]), (0, max_shape[1] - array.shape[1]), (0, max_shape[2] - array.shape[2]), (0, max_shape[3] - array.shape[3])], mode='constant') for array in x]\n","\n","# 將填充後的列表轉換為 NumPy 數組\n","x_padded = np.array(x_padded)\n","\n","# 打印填充後的 x 的形狀\n","print(\"Padded x shape:\", x_padded.shape)"]},{"cell_type":"markdown","metadata":{"id":"zitqVch_j5Hw"},"source":["轉為 DataFrame 並將分類結果=null的去掉"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1716633480293,"user":{"displayName":"木小也","userId":"02664299348038047142"},"user_tz":-480},"id":"VGLOvvnwjn9W","outputId":"8172766d-d0bd-44d5-a088-f0cbc9afc785"},"outputs":[{"name":"stdout","output_type":"stream","text":["DataFrame 的形狀: (101, 230400)\n"]}],"source":["# 將四維陣列轉換為二維 DataFrame\n","x_reshaped = x_padded.reshape((x_padded.shape[0], -1))\n","x_df = pd.DataFrame(x_reshaped)\n","\n","print(\"DataFrame 的形狀:\", x_df.shape)\n","x_df.to_csv('x_img_test_data.csv', index=False)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["x_df shape:  (101, 230401)\n","刪除 x_df[Classification] = NaN 的列後 x_df shape:  (101, 230401)\n","x data complete!\n"]}],"source":["\n","# 刪除 x_df['Classification'] = 'NaN' 的列\n","x_df['Classification'] = Classification\n","print('x_df shape: ', x_df.shape)\n","\n","x_df = x_df.dropna(subset=['Classification'])\n","print('刪除 x_df[Classification] = NaN 的列後 x_df shape: ', x_df.shape)\n","\n","# 分類成6組\n","x_df12 = x_df[(x_df.Classification == 1) | (x_df.Classification == 2)]\n","x_df13 = x_df[(x_df.Classification == 1) | (x_df.Classification == 3)]\n","x_df14 = x_df[(x_df.Classification == 1) | (x_df.Classification == 4)]\n","\n","x_df23 = x_df[(x_df.Classification == 2) | (x_df.Classification == 3)]\n","x_df24 = x_df[(x_df.Classification == 2) | (x_df.Classification == 4)]\n","x_df34 = x_df[(x_df.Classification == 3) | (x_df.Classification == 4)]\n","\n","# x_data.csv\n","x_df.to_csv('x_data.csv', index=False)\n","\n","x_df12.to_csv('x_data12.csv', index=False)\n","x_df13.to_csv('x_data13.csv', index=False)\n","x_df14.to_csv('x_data14.csv', index=False)\n","\n","x_df23.to_csv('x_data23.csv', index=False)\n","x_df24.to_csv('x_data24.csv', index=False)\n","x_df34.to_csv('x_data34.csv', index=False)\n","print('x data complete!')"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNFtFO/PkwgXIDQz21ItdBY","collapsed_sections":["ojwVhnFBEtSF","vcC1D0MM11Eq","mWZ8FkfN17ch","7PvSnqUjqEIt"],"provenance":[]},"kernelspec":{"display_name":"Python 3.7.16 ('tensorflow')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.16"},"vscode":{"interpreter":{"hash":"9d666d82339d4ec6598db6520b8ef6e55f52b78af793bca546f20d1c79188d15"}}},"nbformat":4,"nbformat_minor":0}
